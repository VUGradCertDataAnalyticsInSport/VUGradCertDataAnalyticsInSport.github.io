<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Session4_MeasurementTheoryTechnologies.utf8</title>
    <meta charset="utf-8" />
    <script src="Session4_MeasurementTheoryTechnologies_files/header-attrs/header-attrs.js"></script>
    <link href="Session4_MeasurementTheoryTechnologies_files/remark-css/default.css" rel="stylesheet" />
    <link href="Session4_MeasurementTheoryTechnologies_files/tachyons/tachyons.min.css" rel="stylesheet" />
    <link href="Session4_MeasurementTheoryTechnologies_files/panelset/panelset.css" rel="stylesheet" />
    <script src="Session4_MeasurementTheoryTechnologies_files/panelset/panelset.js"></script>
    <link href="Session4_MeasurementTheoryTechnologies_files/xaringanExtra-extra-styles/xaringanExtra-extra-styles.css" rel="stylesheet" />
    <script type="application/json" id="xaringanExtra-editable-docid">{"id":"x974325184e64ee7a6ef2bf78fcdf43b","expires":1}</script>
    <script src="Session4_MeasurementTheoryTechnologies_files/himalaya/himalaya.js"></script>
    <script src="Session4_MeasurementTheoryTechnologies_files/js-cookie/js.cookie.js"></script>
    <link href="Session4_MeasurementTheoryTechnologies_files/editable/editable.css" rel="stylesheet" />
    <script src="Session4_MeasurementTheoryTechnologies_files/editable/editable.js"></script>
    <link rel="stylesheet" href="VictoriaUniversity.css" type="text/css" />
    <link rel="stylesheet" href="VictoriaUniversity-fonts.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">

class: bottom, left
background-image: url(https://img.rawpixel.com/s3fs-private/rawpixel_images/website_content/pf-ake3293-num.jpg?w=1300&amp;dpr=1&amp;fit=default&amp;crop=default&amp;q=80&amp;vib=3&amp;con=3&amp;usm=15&amp;bg=F4F4F3&amp;ixlib=js-2.2.1&amp;s=271e09ae78b015fcdbdd7fff7b61a989)
background-size: cover 

.NonVU[
# **Measurement Theory**

## Alice Sweeting, PhD
]
 










---
class: left, top
.center[
# Measurements in Sports Analytics 
]


**Validity:** The ability of a tool or technology to reflect what it is designed to measure.

--

**Reliability:** The consistency of these measurements, from a tool or technology.

--

.center[
&lt;img src= "https://www.scienceforsport.com/wp-content/uploads/2018/04/Reliability-scaled.jpg", align="middle", width="55%"&gt;
]

.right[
.citation[
Image source: [Science for Sport](https://www.scienceforsport.com/reliability/)]
]

???
- It is extremely important to ensure that the measurements made as part of research or athlete support work in sports analytics are adequately reliable and valid. That is, they measure what they are designed to measure and they do so consistently.
-  Common measurements exist on different scales, for example, the position of an athlete on the field or court, their body weight, the wind direction at training which may impact shot on goals at training, how they rate their percevied exertion (on a scale) after training. All of these types are measured on different scales. 
- Given that athletic performance, especially at the elite level, is often determined by very small margins or changes, it is important the tools we use to measure performance and these changes, are sensitive enough to detect small and meaningful change.

---
class: left, top
.center[
# Validity


### The ability of a tool or technology to reflect what it is designed to measure.

]
--

#### Content-related Validity 

**Face (or logical) Validity**: Does the test (or tool) measure what it claims to measure?

???
- Least sophisticated measure, as it is difficult to assess
- Asks people (if a test) to rate if the test is suitable or adequate for measuring what it is designed to measure

--

**Construct Validity**: Does the test (or tool) relate to underlying theoretical concepts?

???
- It can be measured by comparing two different groups of subjects with different abilities.
- For example, if we had a kicking accuracy test and we knew it could discriminate between elite and beginner athletes. 
-  For example, if one wished to analyse the construct validity of a test of cycling performance, a comparison of the performance of a group of professional cyclists could be compared with a group of recreational cyclists. A test with good construct validity would easily discriminate between the two groups.

--

&lt;br&gt;
#### Criterion-related Validity

**Concurrent Validity**: Does the test (or tool) correlate with a criterion measure?

???
- More objective method of assessment
- Measuring the output of a tool or technology against a gold-standard or accepted-criterion
- GPS/ wearable tracking systems that measure postion and in turn the velocity of players, compared to a criterion or gold-standard for assessing human movement (Vicon/ optical tracking systems)

--

**Predictive Validity**: Does the test (or tool) predict later performance on a related criterion?

.citation[Currell, K., &amp; Jeukendrup, A. E. (2008). Validity, reliability and sensitivity of measures of sporting performance. Sports medicine, 38(4), 297-316.]

???
- An example of this type of validity is predicting performance from a test of maximal oxygen uptake (V̇O2max) and peak power output (Wmax), with Wmax explaining 94% of the variance in 20-km time-trial performance and V̇O2max 82% of the variance
- Or the ability of an athlete to be selected in a draft or team, based on their performance on a specific test.

---
class: center, middle
## What are some ways that validity (poor or good) could impact data collected for sports analytics use?

--

### For example, a new wearable sensor is introduced that claims to be highly accurate for measuring the velocity of a team-sport athlete during training. However, the sensor is yet to be validated, against an acceptable criteria?


---
class: left, top
.center[
# Reliability


### The consistency of a result, from a tool or technology, over a period of time.

]
--

**Repeatability**: Variation in measurement/ output from a test (or tool) under the exact same conditions, for the same persons/ people, over a period of time

???
- Classic example is standing on scales, in the morning and wearing the same clothes. Stand on the scales once, then hop off and stand on scales again

--

**Reproducibility**: Variation in measurement/ output from a test (or tool) under different conditions, for the same persons/ people, over a period of time

???
- Classic example is standing on scales, in the morning and wearing the same clothes. Stand on the scales once, then hop off and stand other scales
- internal consistency reliability is the variability between repeated trials within a day
- Stability reliability was defined as the day-to-day variability in measurements (most common type)
- Objectivity is the degree to which different observers agree on the measurements and is sometimes referred to as rater reliability 

---
class: left, top
.center[
# Reliability


### The consistency of a result, from a tool or technology, over a period of time.
]

**Repeatability**: Variation in measurement/ output from a test (or tool) under the exact same conditions, for the same persons/ people, over a period of time

**Reproducibility**: Variation in measurement/ output from a test (or tool) under different conditions, for the same persons/ people, over a period of time

.center[
### Measurement Error]

--

**Systematic Bias**: A general trend for measurements to be different in a particular direction (either positive or negative) between repeated tests

???
- with each assessment of measurement error. These are systematic bias and random error. The sum total of these components of variation is known as total error
- There might be a trend for a retest to be higher than a prior test due to a learning effect being present.
- For example, found a biasdue to learning effects for the measurement of back strength using a portable dynamometer. Bias may also be due to there being insufficient recovery between tests. In this case, a retest would show a ‘worse’ score than a prior test. It may be that, after a large number of repeated tests, systematic bias due to training effects (if the test is physically challenging) or transient increases in motivation becomes apparent

--

**Random Error**: Large amounts of random differences could arise due to inherent biological or mechanical variation, or inconsistencies in the measurement protocol.

.citation[Atkinson, G., &amp; Nevill, A. M. (1998). Statistical methods for assessing measurement error (reliability) in variables relevant to sports medicine -. Sports Medicine, 26(4), 217–238]

???
- e.g. not controlling posture in a consistent way during measurements of muscle strength


---
class: center, middle
## What are some ways that reliability could impact data collected for sports analytics use?

--

### For example, the new sensor introduced to measure a team-sport athlete's speed has large variation in detecting velocity, during 2 x (single) 20 m sprint tests?

---
class: left, top
.center[
# Measurement Error


### How does the measurement error relate to the magnitude of the measured variable?
]

**Heteroscedastic**: The amount of random error increases as the measured values increase (depature from a normal variation or skewness)

**Homoscedastic**: No relation between the error and the size of the measured value 

.center[
&lt;img src= "https://www.scienceforsport.com/wp-content/uploads/2018/04/Fig-4.jpg", align="middle", width="45%"&gt;
]

.citation[
Image source: [Science for Sport](https://www.scienceforsport.com/reliability/)
]

---
class: left, top
.center[
# Statistical Distributions - Normal


&lt;img src= "https://blogs.sas.com/content/iml/files/2019/07/rule6895.png", align="middle", width="75%"&gt;
]

.citation[
Image source: [SAS](https://blogs.sas.com/content/iml/files/2019/07/rule6895.png)
]


???
In a typical, normally distributed data set, a centred bell curve demonstrates that 95% of the data revolves around the mean by ±2 Standard Deviations. In this case, the normality of distribution can be assumed.

---
class: left, top
.center[
# Statistical Distributions - Skewed 


&lt;img src= "https://media.springernature.com/lw685/springer-static/image/art%3A10.1186%2Fs12859-020-03892-w/MediaObjects/12859_2020_3892_Fig1_HTML.png", align="middle", width="60%"&gt;
]
&lt;br&gt;

.citation[
de Torrenté, L., Zimmerman, S., Suzuki, M. et al. (2020).
]


???
Bi-modal = Distribution has two humps (each being a relative mode)

---
class: center, top
# Determining Reliability

&lt;img src= "https://media.springernature.com/full/springer-static/image/art%3A10.2165%2F00007256-200838040-00003/MediaObjects/40279_2012_38040297_Tab1.jpg?as=webp", align="middle", width="90%"&gt;

.citation[Table from: Currell, K., &amp; Jeukendrup, A. E. (2008). Validity, reliability and sensitivity of measures of sporting performance. Sports medicine, 38(4), 297-316.]

---
class: center, top
# Measurement Properties


&lt;img src= "https://www.researchgate.net/profile/Samuel-Robertson-2/publication/312070804/figure/fig1/AS:447126816727040@1483614748189/Taxonomy-including-the-initial-measurement-properties-and-feasibility-as-sent-to.png", align="middle", width="60%"&gt;

.citation[Robertson, S. J., Burnett, A. F., &amp; Cochrane, J. (2014). Tests examining skill outcomes in sport: a systematic review of measurement properties and feasibility. Sports Medicine, 44(4), 501-518.]

???
-  Test–retest reliability: The consistency of performer/s scoring over repeated rounds of testing
-  Inter-rater reliability: the level of agreement between scoring/assessing when undertaken by two or more raters
- Intra-rater: defined as the agreement among two or more trials administered or scored by the same rater 
- Content validity: How well a specific test measures what it intends to measure
- Construct validity: The ability of the testing instrument to measure a theoretical construct of performance.
  Discriminative: the ability of the test to discriminate between performers of different ability (as rated by another measure)
  Convergent: the ability of the test to relate with alternate measures of either the same construct or other associated variables
- Criterion validity: The ability of a test to show good agreement with an external measure or gold standard protocol
  Concurrent: relationship of test score to participant score/rankings in an alternate form of measurement
  Predictive: relationship of test score with future results in a relevant sporting competition or performance
- Responsiveness (sensitivity): The ability of a test to detect worthwhile and ‘real’ skill improvements in its intended population between initial bout of testing and subsequent rounds 
-  Minimum important change or difference provided: Information relating to the minimum important change or minimum important difference
Feasibility and limitations
Practicality and limitations: The ease in which a test can be undertaken, administered and scored. Limitations relating to findings and interpretability of the test acknowledged and stated in study
Test context: Information relating to the anticipated use and context of the test provided
Test duration: Expected or actual duration of the testing protocol reported

---
class: bottom, left, inverse
background-image: url(https://img.rawpixel.com/s3fs-private/rawpixel_images/website_content/a009-kaboompics-814.jpg?w=1300&amp;dpr=1&amp;fit=default&amp;crop=default&amp;q=80&amp;vib=3&amp;con=3&amp;usm=15&amp;bg=F4F4F3&amp;ixlib=js-2.2.1&amp;s=d4711c3871b15fbbe78c37229127ba58)
background-size: cover 

# Test Your Knowledge
 
---
class: top, right, inverse
background-image: url(https://img.rawpixel.com/s3fs-private/rawpixel_images/website_content/pd36-5-sts079-810-028.jpg?w=1300&amp;dpr=1&amp;fit=default&amp;crop=default&amp;q=80&amp;vib=3&amp;con=3&amp;usm=15&amp;bg=F4F4F3&amp;ixlib=js-2.2.1&amp;s=468d530e466f4194cc5f3bb9af380a8c)
background-size: cover 

# Technologies for Sports Analytics
 

---
class: top, right, inverse
background-image: url(https://images.catapultsports.com/wp-content/uploads/2018/05/Fundamentals.jpg)
background-size: cover 

# Global Positioning Systems (GPS)

.small[.left[.bottom[Image source: Catapult Sports]]]

???
- Over more than a decade, Global Positioning System (GPS)-based wearable-tracking devices have been widely used to monitor outdoor training allowing a better understanding of the physical requirements of sport while being less time-consuming than traditional time-motion analysis
- these devices provide for real-time movement analysis and feedback that can be directly incorporated into the training regime. Nevertheless, the use of GPS-based devices presents certain limitations: a) they cannot be used indoors [3], and b) questionable validity and reliability to accurately assess short, high-intensity movements due to its low sampling rate (1–10 Hz)

---
class: top, center
# Local Positioning Systems (LPS)

&lt;img src= "https://kinexon.com/uploads/images/Sports/191015_Sports_KINEXONSystem_Courts_Basketball_App.gif", align="middle", width="70%"&gt;

.citation[Image source: Kinexon]

???
- Good validity and reliability, especially for indoor venues
- Still requires physical wearing of a unit and for the court/ playing area to be mounted with anchor nodes or localised stations that transmit radio-frequency signals.
- These anchor stations can be setup locally, but surveying and mapping the area (etc, conducting a survey using a highly precise tool, to measure known boundaries of the court or playing area) takes time

---
class: top, center
# Optical Tracking Systems

&lt;img src= "https://s.wsj.net/public/resources/images/BN-OJ880_Second_J_20160608122233.jpg", align="middle", width="75%"&gt;

.citation[Image source: Second Spectrum]

???
- multi-camera systems that use image-processing techniques (i.e., motion capture) to determine the position of an athlete within a particular physical space. 
- This approach is desirable because it is less invasive to the athlete as it does not require the use of a wearable device. Advances in computer processing (e.g., software algorithms and hardware) continue to make this approach more and more desirable, 
- but the currently available systems suffer from two limitations: a) their use is generally confined to indoor sports because tracking accuracy depends upon the size of the physical space, and b) these systems require post-event processing to accurately determine player position.

---
class: top, center
# Accelerometers

&lt;img src= "https://images.squarespace-cdn.com/content/v1/51a6c5dae4b0fd1b00158d2c/1562875440691-XNHZMYRHSFZAUP21BM9B/ke17ZwdGBToddI8pDm48kIhCaK32WXjH_xT_w8CyIId7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UUrKb3QJNWFYPU4uNVJqb2OAeIRGflpjVO4vp-FyeNtsq48P6Er5hTXB8mTK70lUqQ/I+Measure+U", align="middle", width="65%"&gt;

.citation[Image source: Indemic]

???
- wearable, acceleration-based tracking devices that incorporate microelectromechanical systems (MEMS) gyroscopes, magnetometers, and accelerometers into a single player-worn unit
- The devices utilize tri-axial accelerometers that are not positional based, but movement based (anterior-posterior, medial-lateral, and vertical) [5], to obtain descriptors of sports activities, such us accelerations, decelerations, jumps, change of direction or other accelerometer-derived measurements
- One such derived measurement is the PlayerLoad™ (Catapult Innovations, Melbourne, Australia), which is used to describe and quantify an athlete’s external workload
- The reliability of the accelerometer is acceptable both within and between devices under controlled laboratory conditions, and between devices during field testing. 
- Accelerometers can be confidently utilized as a reliable tool to measure physical activity in team sports across multiple players and repeated bouts of activity
- Limitation for sports analytics is their lack of positional information, so unable to track athlete/ team-mate/ opponent etc relative to court or field of interest

---
class: top, center
# Notational Analysis &amp; Performance Indicators

&lt;img src= "https://hudl-content.s3.amazonaws.com/craft/_1200xAUTO_crop_center-center_none/Coding-HSC-Replay.png?mtime=20200114164751", align="middle", width="75%"&gt;

.citation[Image source: Hudl]

???
- Vision is coded live or post hoc, for example, by pressing a button on a screen (typically known as a code window) each time an event happens. For example, kicks and handballs or shots on goal. 
- The usual way of reporting on performance indicators for game sports is to use frequencies, or relative frequencies, of behavioural occurrences
- These frequency counts provide summary statistics for parts of a match, for a single match, or for several matches aggregated. These types of descriptive statistics, however, do not contain information on the sequential context of the game (for example, what series of actions led to a specific shot on the goal), nor do they report on the situational context of the specific action (for example, was the observed behaviour produced from a fast break or from a static position)
- There are different types of performance indicator used in performance analysis of sport ranging from timings measured on a ratio scale, to event types, playing areas, players involved and event outcomes that are measured on nominal scales. 
-  With respect to observational measurements, as used in notational analysis, reliability is typically assessed using measures of intra- and inter-observer agreement
- How reliable and stable are you, when you code a quarter or game, then how stable or reliable are you compared to someone else.
- This can be calculated by coding a quarter or phase of play one week, the returning the next week and recoding the same piece of footage. Then comparing results with that from another person who completed their own coding

---
class: top, center
# Notational Analysis &amp; Performance Indicators

&lt;img src= "https://www.researchgate.net/profile/Martin-Lames/publication/233653583/figure/fig1/AS:858450355576834@1581681922567/The-coupling-of-competition-and-training-by-game-observation-as-a-three-step-process.png", align="middle", width="70%"&gt;

.citation[Lames, M., &amp; Hansen, G. (2001). Designing observational systems to support top-level teams in game sports. International journal of performance analysis in sport, 1(1), 83-90.]

???
- The usefulness of practical performance analysis lies in the amount of support that it provides to sports practice. This figure details The coupling of competition and training by game observation as a three-step process
- The first step, a detailed description of competition behaviour is required using an appropriate observational system. The quality of this description depends on the reliability of the observation process and measurement consistency.
- the second step, a diagnostic approach is used in which the information is analysed and cues detected for training purposes, particularly cues indicating weaknesses or strengths in performance. Requires more than just observational data. 
- other factors include the individual circumstances such as tactics and strategy, as well as situational aspects such as the psychological, physical and cognitive processes that occur during a game, the quality of the opponent and the level of preparation of the players. An interpretive approach!
- In the third step the results of the diagnosis must be transferred into practical considerations by identifying a list of possible objectives for training. The practical implementation of the interpretation from game observation thus requires a profound knowledge in training methodology as well as a detailed involvement in the training process under consideration

---
class: top, center
# Linear Position Transducers

&lt;img src= "https://kinetic.com.au/images/GymAware_landing.jpg", align="middle", width="50%"&gt;

.citation[Image source: Kinetic]

???
- Is valid for accurately measuring peak velocity during lifts and can therefore be used to autoregulate load during strength-training based on athlete’s recovery level
- concurrent validity and test-retest reliability of a linear position transducer (LPT) for the squat jump (SJ) and counter-movement jump (CMJ) height
- Twenty-eight subjects (25.18 ± 7.1 years) performed three SJs followed by three CMJs using a force plate concurrently with the LPT to test validity. Subjects returned on a separate day, at least 48 h apart, to measure test-retest reliability.

---

class: top, center
# Linear Position Transducers - SJ &amp; CMJ

&lt;img src= "https://www.mdpi.com/sports/sports-06-00177/article_deploy/html/images/sports-06-00177-g002-550.jpg", align="middle", width="60%"&gt;

???
- Validity Results from the paired t-test showed a statistically significant difference between the force plate and GymAware for both SJ (95% CI: 7.52 cm to 8.50 cm; p &lt; 0.001) and CMJ (95% CI: 8.18 cm to 9.18 cm; p &lt; 0.001), while Bland–Altman tests revealed that the GymAware LPT overestimated the jump heights for both SJ (mean difference (MD): 8.01 ± 2.93 cm) and CMJ (MD: 8.68 ± 3.00 cm).
- here we have the mean difference of vertical jump height obtained from the force plate compared to the GymAware LPT for (a) squat jump height and (b) counter-movement jump height. Each point corresponds to each of the 3 jumps from each subject from both days.

--

&lt;img src= "https://www.mdpi.com/sports/sports-06-00177/article_deploy/html/images/sports-06-00177-g003-550.jpg", align="middle", width="60%"&gt;

.citation[Wadhi et al., (2018)]

???
- Bland–Altman difference vs. average plots depicting vertical jump height obtained from GymAware LPT—force plate vs. average of GymAware LPT and force plate for (a) squat jump height and (b) counter-movement jump height. Each point corresponds to each of the 3 jumps from each subject from both days.
- absolute vertical jump heights extrapolated from the GymAware need to be used with precaution. 
- While it is difficult to pinpoint the exact reasoning for the inflated jump heights, it could be due to the overestimation of other jump performance metrics (i.e., power and velocity) demonstrated by LPTs
- In conclusion, GymAware overestimates vertical jump height not just in athletes (e.g., female volleyball athletes), but also in a more heterogeneous population

---
class: top, center
# Power Meters

&lt;img src= "https://www.sram.com/globalassets/image-hierarchy/sram-product-root-images/power-meters/power-meters/pm-force-d1/4835sidel.jpg", align="middle", width="85%"&gt;

.citation[Image source: SRAM]

???
- Power is equal to work over time. power is a direct means of measuring intensity, which is considered by many to be the most important variable in a successful training program
- The use of power meters enables the assessment of cyclists’ training and racing intensity zones according to their skills and thus to their race performance profile
- These data enable the coach and athlete to have measurements of intensity in real cycling locomotion in the field, thus allowing training programs to be developed using power output
- The SRM power meter (pictured) is the most commonly used system in cycling, particularly in professional and amateur racing.
- The SRM system is a crankset that includes a number of strain gauges (4-20 depending on the model used) located between the crank axle and the chainring. The SRM is considered as a gold standard measurement system due to its high validity, reliability and sensitivity during the measure (± 1% average error after calibration procedure performed under standard environmental conditions). This 1% average error represents changes in power output measurements of 2 W in endurance (200 W) and 20 W during sprints (2000 W)
- However, how cost and requires mounting on on your bike

---
class: top, center
# Power Meters

&lt;img src= "https://www.velonews.com/wp-content/uploads/sites/5/2018/06/5P5A5615.jpg", align="middle", width="65%"&gt;

.citation[Image source: Velonews]

???
- The Powertap (PWT, Saris Cycling Group, Madison, USA) is also considered a valid and reliable power meter when compared with the SRM4 or a dynamic calibration rig
- The PWT device measures the PO with strain gauges located in the hub of the rear wheel

---
class: top, center
# Power Meters

&lt;img src= "https://30geqe1ofsyn2b4c79ue9eya-wpengine.netdna-ssl.com/us/wp-content/uploads/sites/2/2018/12/1442x1030bluelogo_0003_IMG_4356-2.jpg", align="middle", width="65%"&gt;

.citation[Image source: Stages Cycling]

???
This power meter uses only the left crank arm for the measurement of power output. The strain gauges are integrated into a small plastic case bonded to the rear side of the left crank arm. As the crank measures the PO on the left side only, the algorithm for power calculation doubles this value to obtain a complete reading for both the left and right sides.

---
class: top, center
# Power Meters

&lt;img src= "https://keyassets.timeincuk.net/inspirewp/live/wp-content/uploads/sites/2/2018/11/Garmin-Vector-3-002_152848802_247633552_174932732_265846422-e1568362091807.jpg", align="middle", width="65%"&gt;

.citation[Image source: Cycling Weekly]

???
- In the Garmin Vector power meter, PO is measured at the pedals where force is applied. The vector power meter measures the slight deflection of the pedal spindle though the entire pedal stroke as well as the 2D force vectors; these data are used to calculate power. The force sensors are housed in both pedals, so that they can independently measure power from each leg and report the total power output considering the balance between both left and right legs

---
class: top, center

&lt;img src= "https://www.researchgate.net/profile/Anthony-Bouillod/publication/311664675/figure/fig1/AS:440563846651904@1482050015025/Bland-Altman-plots-of-the-differences-between-a-POSRM-and-POPWT-b-POSRM-and-POSTG-and.png", align="middle", width="50%"&gt;

.citation[Bouillod, A., Pinot, J., Soto-Romero, G., Bertucci, W., &amp; Grappe, F. (2017). Validity, sensitivity, reproducibility, and robustness of the PowerTap, Stages, and Garmin Vector power meters in comparison with the SRM device. International Journal of Sports Physiology and Performance, 12(8), 1023-1030.]

???
- Bland-Altman plots of the differences between a) POSRM and Power Tap, b) POSRM and Stages and c) POSRM and Garmin Vector power meters during the sub-maximal incremental test. The dashed line represents the mean bias whereas the solid lines represent the high and low 95% confidence interval (CI).
- The powertap power meter can be considered a suitable device for PO measurement during cycling. The stages and vector should be treated with some caution given the presence of significant differences when they are compared with the SRM device
- The use of accurate devices such as SRM and PWT is required for coaches and scientists to enable the assessment of cyclists’ intensity zones and to establish a long-term power profile of individual performance


---
class: top, center
# Other Data Sources for Sports Analytics

.NonVU[
## Athlete wellness/ wellbeing questionnaires  
]

--

.NonVU[
## Ratings of Perceived Exertion (RPE)
]

--

.NonVU[
## Semi-structured Interviews
]

--
.NonVU[
## Others?
]

.left[
.can-edit.key-likes[

]
]

---
class: top, left
.center[
# Tips for Analysing Research Articles on Technologies
]

* Is validity and reliability (of the exact make/ model) described in the paper?

--

* Who are the participants (and their respective skill level) in validity and reliability studies?

--

* Has the raw data been examined? Or is it an average? A rolling average?

--

* How feasible is the tool/ technology for a practical setting?

--

.center[
### Any other tips?
]

.can-edit.key-tips[

]



---
class: top, right, inverse
background-image: url(https://img.rawpixel.com/s3fs-private/rawpixel_images/website_content/p-424-felix-2081-01.jpg?w=1300&amp;dpr=1&amp;fit=default&amp;crop=default&amp;q=80&amp;vib=3&amp;con=3&amp;usm=15&amp;bg=F4F4F3&amp;ixlib=js-2.2.1&amp;s=41442fa35c9237cacc9fdd0d31f4db16)
background-size: fill 
.NonVU[
## Test Your Knowledge
]

--

.NonVU[
## Searching for Sports Analytics Technologies/ Data Sources
]

--

.NonVU[
## Assessment 2
]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="https://platform.twitter.com/widgets.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "github",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
