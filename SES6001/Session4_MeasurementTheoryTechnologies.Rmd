---
output:
  xaringan::moon_reader:
    css: [default, "VictoriaUniversity.css", "VictoriaUniversity-fonts.css"]
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
      ratio: 16:9 
      beforeInit: "https://platform.twitter.com/widgets.js"
      
---
class: bottom, left
background-image: url(https://img.rawpixel.com/s3fs-private/rawpixel_images/website_content/pf-ake3293-num.jpg?w=1300&dpr=1&fit=default&crop=default&q=80&vib=3&con=3&usm=15&bg=F4F4F3&ixlib=js-2.2.1&s=271e09ae78b015fcdbdd7fff7b61a989)
background-size: cover 

.NonVU[
# **Measurement Theory**

## Alice Sweeting, PhD
]
 
```{r setup, include=FALSE}
options(htmltools.dir.version = FALSE, knitr.table.format = "html")
knitr::opts_chunk$set(fig.retina = 3, warning = FALSE, message = FALSE)
library(icon)      
library(tidyverse) 
library(emo) 
library(fontawesome)

# <img class="logoposLB" src="TrackLogo.png", width=16%>   
```

```{r xaringan-tachyons, echo=FALSE}
xaringanExtra::use_tachyons()
```

```{r xaringan-panelset, echo=FALSE}
xaringanExtra::use_panelset()
```

```{r xaringan-extra-styles, echo=FALSE}
xaringanExtra::use_extra_styles(
  hover_code_line = TRUE,         #<<
  mute_unhighlighted_code = TRUE  #<<
)
```

```{r xaringan-editable, echo=FALSE}
xaringanExtra::use_editable(expires = 1)
```

---
class: left, top
.center[
# Measurements in Sports Analytics 
]


**Validity:** The ability of a tool or technology to reflect what it is designed to measure.

--

**Reliability:** The consistency of these measurements, from a tool or technology.

--

.center[
<img src= "https://www.scienceforsport.com/wp-content/uploads/2018/04/Reliability-scaled.jpg", align="middle", width="55%">
]

.right[
.citation[
Image source: [Science for Sport](https://www.scienceforsport.com/reliability/)]
]

???
- It is extremely important to ensure that the measurements made as part of research or athlete support work in sports analytics are adequately reliable and valid. That is, they measure what they are designed to measure and they do so consistently.
-  Common measurements exist on different scales, for example, the position of an athlete on the field or court, their body weight, the wind direction at training which may impact shot on goals at training, how they rate their percevied exertion (on a scale) after training. All of these types are measured on different scales. 
- Given that athletic performance, especially at the elite level, is often determined by very small margins or changes, it is important the tools we use to measure performance and these changes, are sensitive enough to detect small and meaningful change.

---
class: left, top
.center[
# Validity


### The ability of a tool or technology to reflect what it is designed to measure.

]
--

#### Content-related Validity 

**Face (or logical) Validity**: Does the test (or tool) measure what it claims to measure?

???
- Least sophisticated measure, as it is difficult to assess
- Asks people (if a test) to rate if the test is suitable or adequate for measuring what it is designed to measure

--

**Construct Validity**: Does the test (or tool) relate to underlying theoretical concepts?

???
- It can be measured by comparing two different groups of subjects with different abilities.
- For example, if we had a kicking accuracy test and we knew it could discriminate between elite and beginner athletes. 
-  For example, if one wished to analyse the construct validity of a test of cycling performance, a comparison of the performance of a group of professional cyclists could be compared with a group of recreational cyclists. A test with good construct validity would easily discriminate between the two groups.

--

<br>
#### Criterion-related Validity

**Concurrent Validity**: Does the test (or tool) correlate with a criterion measure?

???
- More objective method of assessment
- Measuring the output of a tool or technology against a gold-standard or accepted-criterion
- GPS/ wearable tracking systems that measure postion and in turn the velocity of players, compared to a criterion or gold-standard for assessing human movement (Vicon/ optical tracking systems)

--

**Predictive Validity**: Does the test (or tool) predict later performance on a related criterion?

.citation[Currell, K., & Jeukendrup, A. E. (2008). Validity, reliability and sensitivity of measures of sporting performance. Sports medicine, 38(4), 297-316.]

???
- An example of this type of validity is predicting performance from a test of maximal oxygen uptake (V̇O2max) and peak power output (Wmax), with Wmax explaining 94% of the variance in 20-km time-trial performance and V̇O2max 82% of the variance
- Or the ability of an athlete to be selected in a draft or team, based on their performance on a specific test.

---
class: center, middle
## What are some ways that validity (poor or good) could impact data collected for sports analytics use?

--

### For example, a new wearable sensor is introduced that claims to be highly accurate for measuring the velocity of a team-sport athlete during training. However, the sensor is yet to be validated, against an acceptable criteria?


---
class: left, top
.center[
# Reliability


### The consistency of a result, from a tool or technology, over a period of time.

]
--

**Repeatability**: Variation in measurement/ output from a test (or tool) under the exact same conditions, for the same persons/ people, over a period of time

???
- Classic example is standing on scales, in the morning and wearing the same clothes. Stand on the scales once, then hop off and stand on scales again

--

**Reproducibility**: Variation in measurement/ output from a test (or tool) under different conditions, for the same persons/ people, over a period of time

???
- Classic example is standing on scales, in the morning and wearing the same clothes. Stand on the scales once, then hop off and stand other scales
- internal consistency reliability is the variability between repeated trials within a day
- Stability reliability was defined as the day-to-day variability in measurements (most common type)
- Objectivity is the degree to which different observers agree on the measurements and is sometimes referred to as rater reliability 

---
class: left, top
.center[
# Reliability


### The consistency of a result, from a tool or technology, over a period of time.
]

**Repeatability**: Variation in measurement/ output from a test (or tool) under the exact same conditions, for the same persons/ people, over a period of time

**Reproducibility**: Variation in measurement/ output from a test (or tool) under different conditions, for the same persons/ people, over a period of time

.center[
### Measurement Error]

--

**Systematic Bias**: A general trend for measurements to be different in a particular direction (either positive or negative) between repeated tests

???
- with each assessment of measurement error. These are systematic bias and random error. The sum total of these components of variation is known as total error
- There might be a trend for a retest to be higher than a prior test due to a learning effect being present.
- For example, found a biasdue to learning effects for the measurement of back strength using a portable dynamometer. Bias may also be due to there being insufficient recovery between tests. In this case, a retest would show a ‘worse’ score than a prior test. It may be that, after a large number of repeated tests, systematic bias due to training effects (if the test is physically challenging) or transient increases in motivation becomes apparent

--

**Random Error**: Large amounts of random differences could arise due to inherent biological or mechanical variation, or inconsistencies in the measurement protocol.

.citation[Atkinson, G., & Nevill, A. M. (1998). Statistical methods for assessing measurement error (reliability) in variables relevant to sports medicine -. Sports Medicine, 26(4), 217–238]

???
- e.g. not controlling posture in a consistent way during measurements of muscle strength


---
class: center, middle
## What are some ways that reliability could impact data collected for sports analytics use?

--

### For example, the new sensor introduced to measure a team-sport athlete's speed has large variation in detecting velocity, during 2 x (single) 20 m sprint tests?

---
class: left, top
.center[
# Measurement Error


### How does the measurement error relate to the magnitude of the measured variable?
]

**Heteroscedastic**: The amount of random error increases as the measured values increase (depature from a normal variation or skewness)

**Homoscedastic**: No relation between the error and the size of the measured value 

.center[
<img src= "https://www.scienceforsport.com/wp-content/uploads/2018/04/Fig-4.jpg", align="middle", width="45%">
]

.citation[
Image source: [Science for Sport](https://www.scienceforsport.com/reliability/)
]

---
class: left, top
.center[
# Statistical Distributions - Normal


<img src= "https://blogs.sas.com/content/iml/files/2019/07/rule6895.png", align="middle", width="75%">
]

.citation[
Image source: [SAS](https://blogs.sas.com/content/iml/files/2019/07/rule6895.png)
]


???
In a typical, normally distributed data set, a centred bell curve demonstrates that 95% of the data revolves around the mean by ±2 Standard Deviations. In this case, the normality of distribution can be assumed.

---
class: left, top
.center[
# Statistical Distributions - Skewed 


<img src= "https://media.springernature.com/lw685/springer-static/image/art%3A10.1186%2Fs12859-020-03892-w/MediaObjects/12859_2020_3892_Fig1_HTML.png", align="middle", width="60%">
]
<br>

.citation[
de Torrenté, L., Zimmerman, S., Suzuki, M. et al. (2020).
]


???
Bi-modal = Distribution has two humps (each being a relative mode)

---
class: center, top
# Determining Reliability

<img src= "https://media.springernature.com/full/springer-static/image/art%3A10.2165%2F00007256-200838040-00003/MediaObjects/40279_2012_38040297_Tab1.jpg?as=webp", align="middle", width="90%">

.citation[Table from: Currell, K., & Jeukendrup, A. E. (2008). Validity, reliability and sensitivity of measures of sporting performance. Sports medicine, 38(4), 297-316.]

---
class: center, top
# Measurement Properties


<img src= "https://www.researchgate.net/profile/Samuel-Robertson-2/publication/312070804/figure/fig1/AS:447126816727040@1483614748189/Taxonomy-including-the-initial-measurement-properties-and-feasibility-as-sent-to.png", align="middle", width="60%">

.citation[Robertson, S. J., Burnett, A. F., & Cochrane, J. (2014). Tests examining skill outcomes in sport: a systematic review of measurement properties and feasibility. Sports Medicine, 44(4), 501-518.]

???
-  Test–retest reliability: The consistency of performer/s scoring over repeated rounds of testing
-  Inter-rater reliability: the level of agreement between scoring/assessing when undertaken by two or more raters
- Intra-rater: defined as the agreement among two or more trials administered or scored by the same rater 
- Content validity: How well a specific test measures what it intends to measure
- Construct validity: The ability of the testing instrument to measure a theoretical construct of performance.
  Discriminative: the ability of the test to discriminate between performers of different ability (as rated by another measure)
  Convergent: the ability of the test to relate with alternate measures of either the same construct or other associated variables
- Criterion validity: The ability of a test to show good agreement with an external measure or gold standard protocol
  Concurrent: relationship of test score to participant score/rankings in an alternate form of measurement
  Predictive: relationship of test score with future results in a relevant sporting competition or performance
- Responsiveness (sensitivity): The ability of a test to detect worthwhile and ‘real’ skill improvements in its intended population between initial bout of testing and subsequent rounds 
-  Minimum important change or difference provided: Information relating to the minimum important change or minimum important difference
Feasibility and limitations
Practicality and limitations: The ease in which a test can be undertaken, administered and scored. Limitations relating to findings and interpretability of the test acknowledged and stated in study
Test context: Information relating to the anticipated use and context of the test provided
Test duration: Expected or actual duration of the testing protocol reported

---
class: bottom, left, inverse
background-image: url(https://img.rawpixel.com/s3fs-private/rawpixel_images/website_content/a009-kaboompics-814.jpg?w=1300&dpr=1&fit=default&crop=default&q=80&vib=3&con=3&usm=15&bg=F4F4F3&ixlib=js-2.2.1&s=d4711c3871b15fbbe78c37229127ba58)
background-size: cover 

# Test Your Knowledge
 
---
class: top, right, inverse
background-image: url(https://img.rawpixel.com/s3fs-private/rawpixel_images/website_content/pd36-5-sts079-810-028.jpg?w=1300&dpr=1&fit=default&crop=default&q=80&vib=3&con=3&usm=15&bg=F4F4F3&ixlib=js-2.2.1&s=468d530e466f4194cc5f3bb9af380a8c)
background-size: cover 

# Technologies for Sports Analytics
 

---
class: top, right, inverse
background-image: url(https://images.catapultsports.com/wp-content/uploads/2018/05/Fundamentals.jpg)
background-size: cover 

# Global Positioning Systems (GPS)

.small[.left[.bottom[Image source: Catapult Sports]]]


---
class: top, center
# Local Positioning Systems (LPS)

<img src= "https://kinexon.com/uploads/images/Sports/191015_Sports_KINEXONSystem_Courts_Basketball_App.gif", align="middle", width="70%">

.citation[Image source: Kinexon]

---
class: top, center
# Optical Tracking Systems

<img src= "https://s.wsj.net/public/resources/images/BN-OJ880_Second_J_20160608122233.jpg", align="middle", width="75%">

.citation[Image source: Second Spectrum]

---
class: top, center
# Accelerometers

<img src= "https://images.squarespace-cdn.com/content/v1/51a6c5dae4b0fd1b00158d2c/1562875440691-XNHZMYRHSFZAUP21BM9B/ke17ZwdGBToddI8pDm48kIhCaK32WXjH_xT_w8CyIId7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UUrKb3QJNWFYPU4uNVJqb2OAeIRGflpjVO4vp-FyeNtsq48P6Er5hTXB8mTK70lUqQ/I+Measure+U", align="middle", width="65%">

.citation[Image source: Indemic]

---
class: top, center
# Manual Event Detection

<img src= "https://hudl-content.s3.amazonaws.com/craft/_1200xAUTO_crop_center-center_none/Coding-HSC-Replay.png?mtime=20200114164751", align="middle", width="75%">

.citation[Image source: Hudl]

---
class: top, center
# Linear Position Transducers

<img src= "https://kinetic.com.au/images/GymAware_landing.jpg", align="middle", width="50%">

.citation[Image source: Kinetic]

---
class: top, center
# Power Meters

<img src= "https://www.sram.com/globalassets/image-hierarchy/sram-product-root-images/power-meters/power-meters/pm-force-d1/4835sidel.jpg", align="middle", width="85%">

.citation[Image source: SRAM]

---
class: top, center
# Other Data Sources for Sports Analytics

.NonVU[
## Athlete wellness/ wellbeing questionnaires  
]

--

.NonVU[
## Ratings of Perceived Exertion (RPE)
]

--

.NonVU[
## Semi-structured Interviews
]

--
.NonVU[
## Others?
]

.left[
.can-edit.key-likes[

]
]

---
class: top, right, inverse
background-image: url(https://img.rawpixel.com/s3fs-private/rawpixel_images/website_content/p-424-felix-2081-01.jpg?w=1300&dpr=1&fit=default&crop=default&q=80&vib=3&con=3&usm=15&bg=F4F4F3&ixlib=js-2.2.1&s=41442fa35c9237cacc9fdd0d31f4db16)
background-size: fill 
.NonVU[
## Test Your Knowledge
]

--

.NonVU[
## Searching for Sports Analytics Technologies/ Data Sources
]

--

.NonVU[
## Assessment 2
]
